<div align="center">  

  
  
  # Hi! I'm William Notaro üëã
  
  **Robotics & Embodied AI**
  
  Visiting Student Researcher at **KTH Royal Institute of Technology** | Honors Student at **Scuola Superiore Meridionale**
  
  [![Email](https://img.shields.io/badge/Email-wn.notaro%40gmail.com-red?style=flat-square&logo=gmail)](mailto:wn.notaro@gmail.com)
  [![LinkedIn](https://img.shields.io/badge/LinkedIn-William%20Notaro-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/william-notaro/)
  
</div>

---

### üöÄ About Me
I'm a Master‚Äôs student in **Automation Engineering and Robotics** bridging the gap between **Generative AI** and **Safety**. 

- üéØ **Currently working on:** Imitation Learning for Bimanual Mobile Manipulation at **KTH**.
- üî≠ **Research focus:** Foundation Models for Robotics, Sim-to-Real Transfer, Formal Verification.

---

### üî¨ Featured Research & Projects

#### ü§ñ A VLM-based Control Framework with Plan Verification - ([repo](link))
*MSc Thesis Project | Supervisor: Prof. A. Finzi*

**The Challenge:** Enabling robots to handle open-world instructions ("Pick up the object that looks like...") while ensuring safety.
* **Method:** Integrated **Vision-Language Models** for semantic reasoning with **PDDL** (Planning Domain Definition Language) for formal plan verification.
* **Result:** Deployed on a real **Franka Research 3**. Achieved **<4mm reprojection error** in grounding.
* **Tech:** ROS 2, Python, PDDL, VLM (Gemini Robotics-ER 1.5).

> [!TIP]
> **Check the Full Video Demo:** [YouTube Video](https://youtu.be/C8rL8y8n__4)
> 
> <img src="./previews/vlm_control_framework.gif" width="600" />

<br>



#### üêï Dynamic Gait Learning via Reinforcement Learning - ([repo](https://github.com/well-iam/biologically-inspired-anymal))
*Advanced Robotics Project | 2025*

**The Challenge:** Training a quadruped robot to execute dynamic gaits in simulation.
* **Method:** Utilized **Isaac Lab** (NVIDIA) and **Reinforcement Learning** (PPO) to train a locomotion policy.
* **Result:** Achieved stable bounding gait at **3 m/s** on ANYmal-C model with 42 min estimated autonomy.
* **Tech:** NVIDIA Isaac Lab, PyTorch, RL.

*![test_text??](previews/field_and_service_git.gif)*

<br>

#### ü¶æ Imitation Learning for Bimanual Mobile Manipulation
*Visiting Researcher @ KTH | Present*

**The Challenge:** Coordinating the Unitree G1 Humanoid for Deformable Object Manipulation.
* **Method:** Investigating **Hybrid Action Spaces** in Imitation Learning to solve long-horizon manipulation tasks.
* **Context:** Working under the supervision of **Prof. Danica Kragic**.
<img src="./previews/building_unitree_support.jpeg" width="200" />

---

### üõ†Ô∏è Technical Stack

| Area | Tools & Frameworks |
| :--- | :--- |
| **Robotics Middleware** | ![ROS2](https://img.shields.io/badge/ROS_2-Humble-22314E?style=flat-square&logo=ros) ![Gazebo](https://img.shields.io/badge/Gazebo-Sim-orange?style=flat-square) |
| **AI & Learning** | ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white) ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat-square&logo=tensorflow&logoColor=white) ![Isaac Lab](https://img.shields.io/badge/NVIDIA-Isaac_Lab-76B900?style=flat-square&logo=nvidia) |
| **Languages** | ![C++](https://img.shields.io/badge/C++-00599C?style=flat-square&logo=c%2B%2B) ![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=ffdd54) ![MATLAB](https://img.shields.io/badge/MATLAB-MathWorks-orange?style=flat-square) |
| **DevOps & Tools** | ![Linux](https://img.shields.io/badge/Linux-Ubuntu-FCC624?style=flat-square&logo=linux) ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat-square&logo=docker&logoColor=white) |

---

<div align="center">
  <small>Last update: Feb 2026 | Based in Stockholm, Sweden üá∏üá™</small>
</div>
